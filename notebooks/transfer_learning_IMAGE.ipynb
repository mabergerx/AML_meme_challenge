{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "new_transfer.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKgR16CwnXJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.xception import Xception\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Flatten, GlobalAveragePooling2D\n",
        "from keras.preprocessing import image\n",
        "from keras import regularizers\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmQ6VntcnXJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of progressively loading images from file\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "dir_path = 'train_set/'\n",
        "# numbers are based on mode, varified with histogram\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "# create generator\n",
        "datagen = ImageDataGenerator(validation_split=0.1)\n",
        "# prepare an iterators for each dataset\n",
        "train_it = datagen.flow_from_directory(dir_path, \n",
        "                                       batch_size=64,\n",
        "                                       target_size=(img_width, img_height),\n",
        "                                       subset='training')\n",
        "val_it = datagen.flow_from_directory(dir_path,\n",
        "                                     batch_size=64,\n",
        "                                     target_size=(img_width, img_height),\n",
        "                                     subset='validation')\n",
        "# confirm the iterator works\n",
        "batchX, batchy = train_it.next()\n",
        "val_batchX, val_batchy  = val_it.next()\n",
        "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCbj0R_inXJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_vgg = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "model_xception = Xception(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAw2k6RRnXJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add a global spatial average pooling layer\n",
        "x = model_xception.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
        "                activity_regularizer=regularizers.l1(0.01))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "# Make an output layer for our 4 classes.\n",
        "predictions = Dense(4, activation='softmax', kernel_regularizer=regularizers.l2(0.01),\n",
        "                activity_regularizer=regularizers.l1(0.01))(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HlIvpAanXJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=model_xception.inputs, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsJTZLlnnXJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mark some layers as not trainable. We experimented with freezing some layers from the pretrained models in order to retain the learned knowledge as it is.\n",
        "\n",
        "# model.get_layer('block1_conv1').trainable = False\n",
        "# model.get_layer('block1_conv2').trainable = False\n",
        "# model.get_layer('block2_sepconv1').trainable = False\n",
        "# model.get_layer('block2_sepconv2').trainable = False\n",
        "# model.get_layer('conv2d_1').trainable = False\n",
        "\n",
        "for layer in model_xception.layers:\n",
        "    layer.trainable = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWRM4wIKnXJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLBb5BVfnXJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8QWevhznXJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import CSVLogger\n",
        "\n",
        "csv_logger = CSVLogger('log_xception.csv', append=True, separator=';')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkWIz_W9nXJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "model.fit_generator(\n",
        "    train_it,\n",
        "    epochs=25,\n",
        "    validation_data=val_it,\n",
        "    callbacks=[csv_logger]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNE7sXRBnXJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.save('xception_model_tf.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "OMm56dlKnXJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s2iOK8tnXJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_test_images_array():\n",
        "    \n",
        "    images = []\n",
        "    \n",
        "    for test_i in os.listdir(\"test_set/\"):\n",
        "        img_path = \"test_set/\"+test_i\n",
        "        img = image.load_img(img_path, target_size=(224, 224))\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = preprocess_input(x)\n",
        "        images.append(x)\n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTY4XRupnXJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images = create_test_images_array()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D58wea--nXJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(preprocess_input(np.expand_dims(image.img_to_array(image.load_img(\"test_set/test_1.jpg\", target_size=(500,400))), axis=0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbCIDWgHnXJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = [model.predict(im) for im in test_images]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COlbwjdjnXJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_classes = [np.argmax(ar) for ar in predictions]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "3PjKf7FJnXJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epFteRXFnXJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mapping = {0: \"funny\", 1: \"hilarious\", 2: \"not_funny\", 3: \"very_funny\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRvaw7xjnXJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_final = [mapping[cl] for cl in prediction_classes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "f9kTWApYnXJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAQwFnkmnXJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_test_set = pd.read_csv(\"test_data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDZP3T43nXJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_test_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbX3DButnXJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_test_set[\"Humour\"] = predictions_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpWm8nGQnXJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_predictions_df(test_data_with_pred):\n",
        "    df = test_data_with_pred[[\"id\", \"Humour\"]]\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYBxd-FvnXJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_predictions_df(real_test_set).to_csv(\"submission_19_xception.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2Xriqa0nXJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}